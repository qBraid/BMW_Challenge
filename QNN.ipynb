{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a57e67-9859-4a67-a7a4-22181509fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#PATH PROCESS\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "# IMAGE PROCESS\n",
    "import cv2\n",
    "# MACHINE LEARNING\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pennylane as qml\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34521522-9086-4211-bdab-c2b04d25a8e7",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6163a9cf-5f14-4e18-808c-e215dd3359a1",
   "metadata": {},
   "source": [
    "To make the 227 x 227 pixel images compatible with quantum computing, we apply a threshold and downsample the image to be 8 x 8 pixels.\n",
    "\n",
    "\n",
    "We have modified the preprocessing from: https://www.kaggle.com/brsdincer/surface-crack-detection-end-to-end-process by Baris Dincer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f37fc3-3d79-4a8b-aee1-8dce7b0f8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surface_Data = Path(\"crack_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f4b31-c3cb-4211-9847-1f668cbca264",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surface_JPG_Path = list(Surface_Data.glob(r\"*/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4cf25-5799-46b1-ba71-69c0fc1d3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surface_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Surface_JPG_Path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d187367-1602-443c-bb87-1bdddae52c59",
   "metadata": {},
   "source": [
    "TO SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c618349-e269-4c90-931a-527654d25a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surface_JPG_Path_Series = pd.Series(Surface_JPG_Path,name=\"JPG\").astype(str)\n",
    "Surface_Labels_Series = pd.Series(Surface_Labels,name=\"CATEGORY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad430e2-b9a3-430a-9cf5-120fe023452d",
   "metadata": {},
   "source": [
    "TO DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d22cf0-8f04-4fd1-8708-05c98f4cc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Surface_Data = pd.concat([Surface_JPG_Path_Series,Surface_Labels_Series],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2bca12-8978-432f-a526-b70b3b603fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Main_Surface_Data.head(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65422c1c-d108-4f4e-b63f-436d71cd2459",
   "metadata": {},
   "source": [
    "TO SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ca97c-36b3-4a94-8cc2-dfd94af8763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Surface_Data = Main_Surface_Data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81026c2c-ecab-4562-99ca-3923acc874d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Main_Surface_Data.head(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8b9f1-b18d-4cb9-8053-ccad957a1203",
   "metadata": {},
   "source": [
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6422d1f7-104f-4864-9b02-cb339d81e19d",
   "metadata": {},
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f58091-1d69-4218-8a9c-7b714606ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_Surface = Main_Surface_Data[Main_Surface_Data[\"CATEGORY\"] == \"Positive\"]\n",
    "Negative_Surface = Main_Surface_Data[Main_Surface_Data[\"CATEGORY\"] == \"Negative\"]\n",
    "\n",
    "Positive_Surface = Positive_Surface.reset_index()\n",
    "Negative_Surface = Negative_Surface.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f3f1d7-1c8e-4c71-afa8-82f8e4769b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_vision(path):\n",
    "    figure = plt.figure(figsize=(8,8))\n",
    "    \n",
    "    Reading_Img = cv2.imread(path)\n",
    "    Reading_Img = cv2.cvtColor(Reading_Img,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.xlabel(Reading_Img.shape)\n",
    "    plt.ylabel(Reading_Img.size)\n",
    "    plt.imshow(Reading_Img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10daa643-9a3b-4e63-95d3-e889e3ef94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greyscale_vision(path):\n",
    "    figure = plt.figure(figsize=(8,8))\n",
    "    \n",
    "    Reading_Img = cv2.imread(path)\n",
    "    Reading_Img = cv2.cvtColor(Reading_Img,cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    plt.xlabel(Reading_Img.shape)\n",
    "    plt.ylabel(Reading_Img.size)\n",
    "    plt.imshow(Reading_Img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae6fcb-3e6d-4f3f-bd40-c158445948e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_vision(path):\n",
    "    figure = plt.figure(figsize=(8,8))\n",
    "    \n",
    "    Reading_Img = cv2.imread(path)\n",
    "    Reading_Img = cv2.cvtColor(Reading_Img,cv2.COLOR_BGR2RGB)\n",
    "    _,Threshold_Img = cv2.threshold(Reading_Img,130,255,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    plt.xlabel(Threshold_Img.shape)\n",
    "    plt.ylabel(Threshold_Img.size)\n",
    "    plt.imshow(Threshold_Img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ceecb-8a0d-4f2d-89ab-faac1f0d4ba1",
   "metadata": {},
   "source": [
    "## SIMPLE VISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7df8b7-a6ff-4f55-b40c-0cb1f7662b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_vision(Main_Surface_Data[\"JPG\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ece1976-015a-4624-945e-53b8dd2eab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "simple_vision(Main_Surface_Data[\"JPG\"][2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e988f41-0671-4b47-b18d-0087b4dcb2a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Positive Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c44e09-0db6-42d9-ab0a-86735cadd86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(4,4,figsize=(10,10))\n",
    "\n",
    "for indexing,operations in enumerate(axis.flat):\n",
    "    \n",
    "    Reading_Img = cv2.imread(Positive_Surface[\"JPG\"][indexing])\n",
    "    Reading_Img = cv2.cvtColor(Reading_Img,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    operations.set_xlabel(Reading_Img.shape)\n",
    "    operations.set_ylabel(Reading_Img.size)\n",
    "    operations.imshow(Reading_Img)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d4891f-428e-44be-8409-e29e742ca4c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Negative Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac84ddf-4048-4b10-a23f-811948a7efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(4,4,figsize=(10,10))\n",
    "\n",
    "for indexing,operations in enumerate(axis.flat):\n",
    "    \n",
    "    Reading_Img = cv2.imread(Negative_Surface[\"JPG\"][indexing])\n",
    "    Reading_Img = cv2.cvtColor(Reading_Img,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    operations.set_xlabel(Reading_Img.shape)\n",
    "    operations.set_ylabel(Reading_Img.size)\n",
    "    operations.imshow(Reading_Img)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f04f62-9efe-41ae-8100-469a26776860",
   "metadata": {},
   "source": [
    "## THRESHOLD VISION\n",
    "\n",
    "We'll use threshold vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52d16c-c8b7-4871-86e5-9844acf243ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_vision(Main_Surface_Data[\"JPG\"][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a6d6b1-dad1-4f55-82ae-2aebdcf9a08a",
   "metadata": {},
   "source": [
    "### Positive Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed032756-08e6-43ca-8c27-0dad69e0e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
    "\n",
    "for indexing,operations in enumerate(axis.flat):\n",
    "    \n",
    "    Reading_Img = cv2.imread(Positive_Surface[\"JPG\"][indexing], cv2.IMREAD_GRAYSCALE)\n",
    "    _,Threshold_Img = cv2.threshold(Reading_Img,100,255,cv2.THRESH_BINARY_INV)\n",
    "    # dsize must be an 8x8 for the PQC.\n",
    "    dsize = (8, 8)\n",
    "\n",
    "    # resize image\n",
    "    Threshold_Img = cv2.resize(Threshold_Img, dsize,cv2.INTER_AREA)\n",
    "    \n",
    "    operations.set_xlabel(Threshold_Img.shape)\n",
    "    operations.set_ylabel(Threshold_Img.size)\n",
    "    operations.imshow(Threshold_Img)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d9970-8609-48c9-8d00-736a5c78e207",
   "metadata": {},
   "source": [
    "### Negative Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1623669-ad48-41b6-8c9b-296c5856eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
    "\n",
    "for indexing,operations in enumerate(axis.flat):\n",
    "    Reading_Img = cv2.imread(Negative_Surface[\"JPG\"][indexing], cv2.IMREAD_GRAYSCALE)\n",
    "    _,Threshold_Img = cv2.threshold(Reading_Img,100,255,cv2.THRESH_BINARY_INV)\n",
    "    # dsize must be an 8x8 for the PQC.\n",
    "    dsize = (8, 8)\n",
    "\n",
    "    # resize image\n",
    "    Threshold_Img = cv2.resize(Threshold_Img, dsize,cv2.INTER_AREA)\n",
    "    operations.set_xlabel(Threshold_Img.shape)\n",
    "    operations.set_ylabel(Threshold_Img.size)\n",
    "    operations.imshow(Threshold_Img)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0b2ce-fa0c-44cb-888f-4e3021596380",
   "metadata": {},
   "source": [
    "We note approximately 5% of the images as having contradicting labels when downsampled.\n",
    "\n",
    "We could follow in the footsteps of Farhi et al. to clean the data further we can discard all the positive and negative images that are misclassified by the downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1922c-dc17-43f5-85e5-66dc5a9c5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    #Create Array of pixel value\n",
    "    #data = cv2.imread(data,cv2.IMREAD_GRAYSCALE)\n",
    "    if np.all(data) == 0:\n",
    "        return data\n",
    "    testdata=data\n",
    "    arr_data=testdata.flatten()/max(testdata.flatten());\n",
    "    encoding_data= np.array([np.round(x,6) for x in arr_data]);\n",
    "    sum_const=np.sqrt(sum(encoding_data*encoding_data))\n",
    "    encoding_norm=encoding_data/sum_const\n",
    "    return encoding_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c400706-69d5-4f5a-8194-96ff38a9f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
    "Reading_Img = cv2.imread(Negative_Surface[\"JPG\"][1], cv2.IMREAD_GRAYSCALE)\n",
    "_,Threshold_Img = cv2.threshold(Reading_Img,100,255,cv2.THRESH_BINARY_INV)\n",
    "# dsize must be an 8x8 for the PQC.\n",
    "dsize = (8, 8)\n",
    "\n",
    "# resize image\n",
    "Threshold_Img = cv2.resize(Threshold_Img, dsize,cv2.INTER_AREA)\n",
    "figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
    "print(Threshold_Img)\n",
    "plt.imshow(Threshold_Img)\n",
    "normalize_data(Threshold_Img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97316554-0a36-4e95-921e-f93e40b74a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies a threshold, resize, then normalize.\n",
    "    img_path: str =  image file path\n",
    "    \"\"\"\n",
    "    # read image\n",
    "    Reading_Img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # apply threshold\n",
    "    _,Threshold_Img = cv2.threshold(Reading_Img,100,255,cv2.THRESH_BINARY_INV)\n",
    "    # dsize must be an 8x8 for the PQC.\n",
    "    dsize = (8, 8)\n",
    "    # resize image\n",
    "    Threshold_Img = cv2.resize(Threshold_Img, dsize,cv2.INTER_AREA)\n",
    "    # normalize image\n",
    "    Threshold_Img = normalize_data(Threshold_Img)\n",
    "    return Threshold_Img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218be475-e090-4c78-b034-a57871a687aa",
   "metadata": {},
   "source": [
    "We will apply this to both the negative and positive surface datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7610f-3f88-4f4a-92d7-6ebdefc6831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to get\n",
    "Negative_Surface['Image_Array']=Negative_Surface['JPG'].apply(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb625289-f625-4c8a-b418-c3153c9589f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_Surface['Image_Array']=Positive_Surface['JPG'].apply(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b35edc-9ffa-457a-9769-242fe28c0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Surface_Data['Image_Array']=Main_Surface_Data['JPG'].apply(preprocess_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3029cb-ecf2-4a61-82b1-066a5cc037fc",
   "metadata": {},
   "source": [
    "We will used the resized arrays as our training feature and the categories as our targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eece88-0882-4338-85d1-200eefb55c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Main_Surface_Data['Image_Array']\n",
    "Y = Main_Surface_Data['CATEGORY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b1abd-7395-43f7-8817-3ca07398ae49",
   "metadata": {},
   "source": [
    "Split the data into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047143f-3277-4f83-ac2a-080569f8d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainy, testy = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031ea6d-a962-483b-8212-92c46f1cae06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2995c3c-b77b-48ab-9459-2b5cba3200ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainy = tf.one_hot(trainy, depth=2)\n",
    "testy = tf.one_hot(testy, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd190e-cc57-4d5e-8e12-05664c407272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259af47-b913-4c3b-ad83-dd392e7d6303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccb392-1eb5-48fc-9d3f-9bb4d0ffcea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[qBraid] Python 3",
   "language": "python",
   "name": "python3_qbraid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
